{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2893eb8-8a5f-42d6-b4b0-40354a872698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Faker in /srv/conda/envs/notebook/lib/python3.11/site-packages (21.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.4 in /srv/conda/envs/notebook/lib/python3.11/site-packages (from Faker) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /srv/conda/envs/notebook/lib/python3.11/site-packages (from python-dateutil>=2.4->Faker) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor, export_graphviz\n",
    "from sklearn import tree\n",
    "import plotly.express as px\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "!pip install Faker\n",
    "from faker import Faker\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c9e985-5439-42c1-a9fa-36d3082528df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a seed for reproducibility\n",
    "np.random.seed(0)\n",
    "\n",
    "# Define the number of users and the range for the counts\n",
    "num_users = 1000\n",
    "max_posts = 10\n",
    "max_friends = 15\n",
    "max_events = 5\n",
    "max_points = 50\n",
    "\n",
    "# Generate random counts for posts, friends, and events\n",
    "posts_counts = np.random.randint(0, max_posts + 1, num_users)\n",
    "friends_counts = np.random.randint(0, max_friends + 1, num_users)\n",
    "events_counts = np.random.randint(0, max_events + 1, num_users)\n",
    "\n",
    "# Generate a random points value for each user\n",
    "points_values = np.random.randint(0, max_points + 1, num_users)\n",
    "\n",
    "# Create a DataFrame for synthetic data\n",
    "synthetic_data = pd.DataFrame({\n",
    "    'UserID': range(1, num_users + 1),\n",
    "    'DistinctPostIDCount': posts_counts,\n",
    "    'DistinctFriendIDCount': friends_counts,\n",
    "    'DistinctEventIDCount': events_counts,\n",
    "    'SumPointsValue': points_values\n",
    "})\n",
    "\n",
    "# Calculate the engagement score based on the provided weights\n",
    "synthetic_data['CalculatedEngagementScore'] = (\n",
    "    0.4 * synthetic_data['DistinctPostIDCount'] +\n",
    "    0.3 * synthetic_data['DistinctFriendIDCount'] +\n",
    "    0.2 * synthetic_data['DistinctEventIDCount'] +\n",
    "    0.1 * synthetic_data['SumPointsValue']\n",
    ")\n",
    "\n",
    "# Feature Engineering\n",
    "synthetic_data['PostsPerFriend'] = synthetic_data['DistinctPostIDCount'] / (synthetic_data['DistinctFriendIDCount'] + 1)  # Avoid division by zero\n",
    "synthetic_data['EventsTimesPoints'] = synthetic_data['DistinctEventIDCount'] * synthetic_data['SumPointsValue']\n",
    "\n",
    "# Shuffle the DataFrame to remove any implicit order\n",
    "synthetic_data = synthetic_data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Generating the complex engagement score\n",
    "def generate_complex_engagement_score(row):\n",
    "    score = (row['DistinctPostIDCount'] ** 1.5 + \n",
    "             np.sqrt(row['DistinctFriendIDCount']) * 2 + \n",
    "             np.log1p(row['DistinctEventIDCount']) * 3 + \n",
    "             np.sqrt(row['SumPointsValue']) * 1.2 +\n",
    "             np.random.normal(0, 2))  # Random noise\n",
    "    return max(0, score)  # Ensuring score is non-negative\n",
    "\n",
    "synthetic_data['ComplexEngagementScore'] = synthetic_data.apply(generate_complex_engagement_score, axis=1)\n",
    "\n",
    "# Optionally save the DataFrame to a CSV file\n",
    "synthetic_data.to_csv('synthetic_data_with_engagement_score.csv', index=False)\n",
    "\n",
    "synthetic_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e8ba16-77a3-49fc-8fbb-c60aea723031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the data for the new linear regression model\n",
    "X = synthetic_data[['DistinctPostIDCount', 'DistinctFriendIDCount', 'DistinctEventIDCount', 'SumPointsValue']]\n",
    "y = synthetic_data['ComplexEngagementScore']\n",
    "\n",
    "# Splitting the dataset into training and testing sets again\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Creating a new model\n",
    "new_model = LinearRegression()\n",
    "\n",
    "# Fitting the model\n",
    "new_model.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions\n",
    "y_pred_new = new_model.predict(X_test)\n",
    "\n",
    "# Evaluating the new model\n",
    "rmse_new = mean_squared_error(y_test, y_pred_new, squared=False)\n",
    "r2_new = r2_score(y_test, y_pred_new)\n",
    "\n",
    "# Coefficients and intercept of the new model\n",
    "coefficients_new = new_model.coef_\n",
    "intercept_new = new_model.intercept_\n",
    "\n",
    "rmse_new, r2_new, coefficients_new, intercept_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a651ec58-d20d-441c-b9e5-12b691bf4fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the actual vs predicted values for the new model\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred_new, color='red')\n",
    "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=2)\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "plt.title('Actual vs Predicted Complex Engagement Scores')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d323e0ce-a746-4c53-ae57-2aa9efe1e3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polynomial features\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_poly = poly.fit_transform(X)\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train_poly, X_test_poly, y_train, y_test = train_test_split(X_poly, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Training the model\n",
    "poly_model = LinearRegression()\n",
    "poly_model.fit(X_train_poly, y_train)\n",
    "\n",
    "# Making predictions\n",
    "y_pred_poly = poly_model.predict(X_test_poly)\n",
    "\n",
    "# Evaluating the model\n",
    "rmse_poly = mean_squared_error(y_test, y_pred_poly, squared=False)\n",
    "r2_poly = r2_score(y_test, y_pred_poly)\n",
    "\n",
    "# Results\n",
    "rmse_poly, r2_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165cb1ad-f079-472e-a4c2-a0492d56636a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features for visualization\n",
    "features = ['DistinctPostIDCount', 'DistinctFriendIDCount', 'DistinctEventIDCount', 'SumPointsValue']\n",
    "\n",
    "# Creating subplots\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Polynomial transformation\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "\n",
    "for i, feature in enumerate(features):\n",
    "    # Define the model\n",
    "    model = LinearRegression()\n",
    "\n",
    "    # Selecting the feature and target for plotting\n",
    "    x = synthetic_data[feature].values.reshape(-1, 1)\n",
    "    y = synthetic_data['ComplexEngagementScore'].values\n",
    "\n",
    "    # Applying polynomial transformation\n",
    "    x_poly = poly.fit_transform(x)\n",
    "\n",
    "    # Fitting the model\n",
    "    model.fit(x_poly, y)\n",
    "\n",
    "    # Predictions for a range of values\n",
    "    x_range = np.linspace(x.min(), x.max(), 100).reshape(-1, 1)\n",
    "    x_range_poly = poly.transform(x_range)\n",
    "    predictions = model.predict(x_range_poly)\n",
    "\n",
    "    # Plotting\n",
    "    axes[i].scatter(x, y, color='blue', label='Original Data')\n",
    "    axes[i].plot(x_range, predictions, color='red', label=f'Polynomial Degree {degree}')\n",
    "    axes[i].set_xlabel(feature)\n",
    "    axes[i].set_ylabel('ComplexEngagementScore')\n",
    "    axes[i].set_title(f'Effect of Polynomial Transformation on {feature}')\n",
    "    axes[i].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1303dc50-9299-4bcb-8b2d-1519435ce15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Ridge and Lasso regression models\n",
    "ridge_model = Ridge(alpha=1.0)\n",
    "lasso_model = Lasso(alpha=0.1)\n",
    "\n",
    "# Fitting the models\n",
    "ridge_model.fit(X_train, y_train)\n",
    "lasso_model.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions\n",
    "y_pred_ridge = ridge_model.predict(X_test)\n",
    "y_pred_lasso = lasso_model.predict(X_test)\n",
    "\n",
    "# Evaluating the models\n",
    "rmse_ridge = mean_squared_error(y_test, y_pred_ridge, squared=False)\n",
    "r2_ridge = r2_score(y_test, y_pred_ridge)\n",
    "rmse_lasso = mean_squared_error(y_test, y_pred_lasso, squared=False)\n",
    "r2_lasso = r2_score(y_test, y_pred_lasso)\n",
    "\n",
    "# Coefficients and intercepts\n",
    "coefficients_ridge = ridge_model.coef_\n",
    "intercept_ridge = ridge_model.intercept_\n",
    "coefficients_lasso = lasso_model.coef_\n",
    "intercept_lasso = lasso_model.intercept_\n",
    "\n",
    "# Preparing the results for display\n",
    "results = {\n",
    "    \"Model\": [\"Linear Regression\", \"Ridge Regression\", \"Lasso Regression\"],\n",
    "    \"RMSE\": [rmse_new, rmse_ridge, rmse_lasso],\n",
    "    \"R2\": [r2_new, r2_ridge, r2_lasso],\n",
    "    \"Coefficients\": [coefficients_new, coefficients_ridge, coefficients_lasso],\n",
    "    \"Intercept\": [intercept_new, intercept_ridge, intercept_lasso]\n",
    "}\n",
    "\n",
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae316b4-10d7-4d7b-85c9-1e88e5be34e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the actual vs predicted values for Ridge Regression\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred_ridge, color='green')\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted by Ridge')\n",
    "plt.title('Ridge Regression: Actual vs Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fc36fc-159a-4613-a472-19b382084fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the actual vs predicted values for Lasso Regression\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred_lasso, color='blue')\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted by Lasso')\n",
    "plt.title('Lasso Regression: Actual vs Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fd2b12-f7e7-41bd-a6c5-3f06833af0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alpha values to try\n",
    "alphas = np.logspace(-4, 4, 9)\n",
    "\n",
    "# Initializing dictionaries to store results\n",
    "ridge_coefficients = {}\n",
    "lasso_coefficients = {}\n",
    "\n",
    "# Ridge Regression\n",
    "for alpha in alphas:\n",
    "    ridge = Ridge(alpha=alpha)\n",
    "    ridge.fit(X_train, y_train)\n",
    "    ridge_coefficients[alpha] = ridge.coef_\n",
    "\n",
    "# Lasso Regression\n",
    "for alpha in alphas:\n",
    "    lasso = Lasso(alpha=alpha)\n",
    "    lasso.fit(X_train, y_train)\n",
    "    lasso_coefficients[alpha] = lasso.coef_\n",
    "\n",
    "# Preparing data for plotting\n",
    "ridge_coefs = pd.DataFrame(ridge_coefficients, index=X.columns).T\n",
    "lasso_coefs = pd.DataFrame(lasso_coefficients, index=X.columns).T\n",
    "\n",
    "ridge_coefs, lasso_coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107d9322-47dc-43c5-aec5-a80b2106c762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alpha values for Ridge regression\n",
    "alphas = np.logspace(-4, 4, 9)\n",
    "\n",
    "# Dictionary to store coefficients\n",
    "ridge_coefficients = {}\n",
    "\n",
    "# Perform Ridge regression for different alpha values\n",
    "for alpha in alphas:\n",
    "    ridge = Ridge(alpha=alpha)\n",
    "    ridge.fit(X_train, y_train)\n",
    "    ridge_coefficients[alpha] = ridge.coef_\n",
    "\n",
    "# Convert coefficients to DataFrame for plotting\n",
    "ridge_coefs = pd.DataFrame(ridge_coefficients, index=X_train.columns).T\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "for column in ridge_coefs.columns:\n",
    "    plt.plot(ridge_coefs.index, ridge_coefs[column], label=column)\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Alpha')\n",
    "plt.ylabel('Coefficients')\n",
    "plt.title('Ridge Coefficients as a Function of the Regularization')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fab4038-55e6-469a-9458-3157e3d2f719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store coefficients\n",
    "lasso_coefficients = {}\n",
    "\n",
    "# Perform Lasso regression for different alpha values\n",
    "for alpha in alphas:\n",
    "    lasso = Lasso(alpha=alpha)\n",
    "    lasso.fit(X_train, y_train)\n",
    "    lasso_coefficients[alpha] = lasso.coef_\n",
    "\n",
    "# Convert coefficients to DataFrame for plotting\n",
    "lasso_coefs = pd.DataFrame(lasso_coefficients, index=X_train.columns).T\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "for column in lasso_coefs.columns:\n",
    "    plt.plot(lasso_coefs.index, lasso_coefs[column], label=column)\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Alpha')\n",
    "plt.ylabel('Coefficients')\n",
    "plt.title('Lasso Coefficients as a Function of the Regularization')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9bc538-5fc1-4da4-80aa-f6344be0536c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfd74eb-c33b-4d46-bfb4-a6495b104197",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
